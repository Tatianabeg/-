{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tatianabeg/-/blob/main/DZ_3_Huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec77f4f5",
      "metadata": {
        "id": "ec77f4f5"
      },
      "source": [
        "# Упрощаем использование TL. Фреймворк Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dd42298",
      "metadata": {
        "id": "3dd42298"
      },
      "source": [
        "## Первый семинар\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6028e90f",
      "metadata": {
        "id": "6028e90f"
      },
      "source": [
        "## Второй семинар\n",
        "\n",
        "![fdbd6488-6edc-4a18-8070-7f587f38bc92.jfif](attachment:fdbd6488-6edc-4a18-8070-7f587f38bc92.jfif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef51fa5",
      "metadata": {
        "id": "fef51fa5"
      },
      "source": [
        "Вы уже получили представление, с чего начинается проект с нейросетями или откуда брать эмбеддинги.\n",
        "\n",
        "- Например, вы можете взять Colab и создать поисковик по изображениям: https://blog.roboflow.com/clip-image-search-faiss/.\n",
        "- Или можете создать рекомендательныю систему по текстовым описаниям товаров: https://www.kaggle.com/code/andrzejpackard/bert-and-faiss-for-recomendation-engine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "312fe8e1",
      "metadata": {
        "id": "312fe8e1"
      },
      "source": [
        "Следующий шаг – упростить себе работу с широчайшим перечнем предобученных моделей.\n",
        "\n",
        "Нам понадобится библиотека transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41cc7bca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41cc7bca",
        "outputId": "8d4151bb-5f8f-4e1b-f04b-12990f378035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fda6bacf",
      "metadata": {
        "id": "fda6bacf"
      },
      "source": [
        "## Почему трансформеры?\n",
        "\n",
        "- Не простые эмбеддинги, а позиционные (часть слова + положение в последовательности)\n",
        "- 10-20 одинаковых модулей, которые постоянно рассылают друг другу \"запросы\"\n",
        "- Каждый модуль практически равен строчке кода в программе (хотя может делать гораздо более сложные вещи)\n",
        "- Очень эффективно вычисляется и распараллеливается\n",
        "\n",
        "В предшествующих (реккурентных) сетях обучение и вычисление велось по цепочке. Тут все параллельно.\n",
        "\n",
        "* GPT3 учитывал 8000.\n",
        "* GPT4 учитывает 32000 токенов в качестве контекста (объем маленькой книги).\n",
        "* Flash attention – 64000 (среднего размера книга)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c48af151",
      "metadata": {
        "id": "c48af151"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb387fff",
      "metadata": {
        "id": "eb387fff"
      },
      "source": [
        "https://www.youtube.com/watch?v=NzLwHcqE6Jw"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a0602ed",
      "metadata": {
        "id": "0a0602ed"
      },
      "source": [
        "Зато... трансформеры требуют огромного количества памяти.\n",
        "\n",
        "* _Stable Diffusion_ – модели от 10 Гб и больше\n",
        "* _GPT_... давайте посмотрим на сайте"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5352d128",
      "metadata": {
        "id": "5352d128"
      },
      "source": [
        "# Что такое Huggingface\n",
        "\n",
        "* Сотни тысяч предобученных моделей\n",
        "* Очень много датасетов (как и в kaggle, и в Google Dataset Search)\n",
        "* HF Spaces\n",
        "\n",
        "Пройдемся по https://huggingface.co/\n",
        "\n",
        "Когда нужно хранить модель локально, а когда лучше пользоваться API?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099de35a",
      "metadata": {
        "id": "099de35a"
      },
      "source": [
        "## Примеры кода (pipeline)\n",
        "\n",
        "Объекты Pipeline: https://huggingface.co/docs/transformers/v4.35.2/en/main_classes/pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae300927",
      "metadata": {
        "id": "ae300927"
      },
      "source": [
        "Демо чат-бота:\n",
        "\n",
        "- https://huggingface.co/tasks/conversational\n",
        "- https://huggingface.co/docs/transformers/v4.35.2/en/main_classes/pipelines#transformers.ConversationalPipeline\n",
        "\n",
        "```python\n",
        "from transformers import pipeline, Conversation\n",
        "\n",
        "chatbot = pipeline(model=\"microsoft/DialoGPT-medium\")\n",
        "conversation = Conversation(\"Going to the movies tonight - any suggestions?\")\n",
        "conversation = chatbot(conversation)\n",
        "conversation.generated_responses[-1]\n",
        ">>> 'The Big Lebowski'\n",
        "\n",
        "conversation.add_user_input(\"Is it an action movie?\")\n",
        "conversation = chatbot(conversation)\n",
        "conversation.generated_responses[-1]\n",
        ">>> \"It's a comedy.\"\n",
        "```\n",
        "\n",
        "Онлайн-демо: https://huggingface.co/spaces/shawhin/vanilla-chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e4b853",
      "metadata": {
        "id": "33e4b853"
      },
      "source": [
        "# Задачи компьютерного зрения\n",
        "\n",
        "* Оценка карты глубины по фотографии: https://huggingface.co/blog/cv_state#support-for-pipelines\n",
        "* Классификация изображений\n",
        "* Сегментация изображений\n",
        "* Перевод изображения в изображение\n",
        "* Детекция объектов\n",
        "* Классификация видео\n",
        "* Классификация без заранее определенных меток (ZeroShot Classification)\n",
        "\n",
        "Перечень задач: https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#computer-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e740d903",
      "metadata": {
        "id": "e740d903"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "depth_estimator = pipeline(task=\"depth-estimation\") # model=\"Intel/dpt-large\"\n",
        "output = depth_estimator(\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B0._%D0%9A%D1%80%D0%B5%D0%BC%D0%BB%D1%8C._%D0%9A%D0%BE%D0%BB%D0%BE%D0%BA%D0%BE%D0%BB%D1%8C%D0%BD%D1%8F_%D0%98%D0%B2%D0%B0%D0%BD%D0%B0_%D0%92%D0%B5%D0%BB%D0%B8%D0%BA%D0%BE%D0%B3%D0%BE_IMG_2111.2_e1b2sm_VIII-2009.jpg/1280px-%D0%9C%D0%BE%D1%81%D0%BA%D0%B2%D0%B0._%D0%9A%D1%80%D0%B5%D0%BC%D0%BB%D1%8C._%D0%9A%D0%BE%D0%BB%D0%BE%D0%BA%D0%BE%D0%BB%D1%8C%D0%BD%D1%8F_%D0%98%D0%B2%D0%B0%D0%BD%D0%B0_%D0%92%D0%B5%D0%BB%D0%B8%D0%BA%D0%BE%D0%B3%D0%BE_IMG_2111.2_e1b2sm_VIII-2009.jpg\")\n",
        "\n",
        "# Вызов этой команды возвращает нам тензор, в котором дана оценочная информация\n",
        "# об удаленности каждого объекта от зрителя (в метрах)\n",
        "output[\"depth\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e76c28a5",
      "metadata": {
        "id": "e76c28a5"
      },
      "source": [
        "Генерация изображений там тоже есть, но, как было сказано, диффузионные модели занимают огромное пространство в памяти."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d36b89f",
      "metadata": {
        "id": "2d36b89f"
      },
      "outputs": [],
      "source": [
        "#!pip install diffusers\n",
        "\n",
        "#from diffusers import DiffusionPipeline\n",
        "#generator = DiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
        "#generator.to(\"cuda\")\n",
        "#image = generator(\"An image of a squirrel in Picasso style\").images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51471259",
      "metadata": {
        "id": "51471259"
      },
      "source": [
        "# Поработаем с текстом"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77ed82e4",
      "metadata": {
        "id": "77ed82e4"
      },
      "source": [
        "Модели, понимающий русский язык: https://huggingface.co/models?language=ru\n",
        "\n",
        "Например, поищем русские модели для перевода текста в речь: https://huggingface.co/docs/transformers/tasks/text-to-speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13bdec9f",
      "metadata": {
        "id": "13bdec9f"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"Den4ikAI/rubert-large-squad\",\n",
        "    tokenizer=\"Den4ikAI/rubert-large-squad\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71dfeb8e",
      "metadata": {
        "id": "71dfeb8e"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"\n",
        "Во́льфганг Амаде́й Мо́царт (нем. Wolfgang Amadeus Mozart, МФА МФА: [ˈvɔlfɡaŋ amaˈdeus ˈmoːtsaʁt](инф.); полное имя — Иога́нн Хризосто́м Во́льфганг Амаде́й Мо́царт; 27 января 1756, Зальцбург — 5 декабря 1791, Вена) — австрийский композитор и музыкант-виртуоз. Один из самых популярных классических композиторов, Моцарт оказал большое влияние на мировую музыкальную культуру.\n",
        "По свидетельству современников, Моцарт обладал феноменальным музыкальным слухом, памятью и способностью к импровизации. Самый молодой член[К 1] Болонской филармонической академии (с 1770 года) за всю её историю, а также самый молодой кавалер ордена Золотой шпоры (1770).\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62730083",
      "metadata": {
        "id": "62730083"
      },
      "outputs": [],
      "source": [
        "result = question_answerer(question=\"Моцарт был кавалером какого ордена?\", context=context)\n",
        "print( result['answer'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4db100",
      "metadata": {
        "id": "ce4db100"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd1cfeb",
      "metadata": {
        "id": "bfd1cfeb"
      },
      "outputs": [],
      "source": [
        "result = question_answerer(question=\"Кем был Моцарт?\", context=context)\n",
        "print( result['answer'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "767c43a2",
      "metadata": {
        "id": "767c43a2"
      },
      "source": [
        "# Домашнее задание\n",
        "\n",
        "Реализуйте классификацию эмоциональной окрашенности текстов при помощи объекта pipeline.\n",
        "\n",
        "1. Найдите тип задач Sentiment Analysis на huggingface.co\n",
        "2. Найдите модель для русского языка (примеры: rubert-tiny2..., rubert-base...)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "YP4zHAlUaJOd"
      },
      "id": "YP4zHAlUaJOd"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "ccF440nNbwAH"
      },
      "id": "ccF440nNbwAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация объекта pipeline с моделью для анализа тональности на русском языке\n",
        "classifier = pipeline('sentiment-analysis', model='seara/rubert-tiny2-russian-sentiment')\n",
        "\n",
        "# Применение классификатора к списку текстов\n",
        "texts = [\n",
        "    \"Отличный товар\",\n",
        "    \"Мне не понравилось\",\n",
        "    \"Прекрасно выглядит, ничего не меняйте!\",\n",
        "    \"Ничего не понял\",\n",
        "    \"У меня не работала розетка, в остальном все отлично\"\n",
        "]\n",
        "\n",
        "predictions = classifier(texts)\n",
        "\n",
        "# Вывод результатов\n",
        "for review, prediction in zip(texts, predictions):\n",
        "    print(f\"Текст: {review} | Эмоциональная окраска: {prediction['label']} | Вероятность: {prediction['score']:.4f}\")"
      ],
      "metadata": {
        "id": "YozzG9CfZGLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d6fb88-9a50-4bc6-952b-955de7ef6224"
      },
      "id": "YozzG9CfZGLF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Текст: Отличный товар | Эмоциональная окраска: positive | Вероятность: 0.9941\n",
            "Текст: Мне не понравилось | Эмоциональная окраска: neutral | Вероятность: 0.5912\n",
            "Текст: Прекрасно выглядит, ничего не меняйте! | Эмоциональная окраска: positive | Вероятность: 0.9389\n",
            "Текст: Ничего не понял | Эмоциональная окраска: negative | Вероятность: 0.5240\n",
            "Текст: У меня не работала розетка, в остальном все отлично | Эмоциональная окраска: positive | Вероятность: 0.6734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e7ff63d",
      "metadata": {
        "id": "8e7ff63d"
      },
      "source": [
        "# Как запустить сервис на основе модели?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52eb3e22",
      "metadata": {
        "id": "52eb3e22"
      },
      "source": [
        "Например, в Gradio:\n",
        "\n",
        "1. https://huggingface.co/spaces/gradio/chatbot\n",
        "2. https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html\n",
        "\n",
        "Или в Huggingface Spaces: https://huggingface.co/spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0437a4ff",
      "metadata": {
        "id": "0437a4ff"
      },
      "source": [
        "# И напоследок поработаем с кодом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c7d302",
      "metadata": {
        "id": "55c7d302"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=\"huggingface/CodeBERTa-small-v1\",\n",
        "    tokenizer=\"huggingface/CodeBERTa-small-v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f817e46",
      "metadata": {
        "id": "7f817e46"
      },
      "outputs": [],
      "source": [
        "python_code = \"\"\"\n",
        "# a list of numbers\n",
        "my_numbers = [10, 8, 3, 22, 33, 7, 11, 100, 54]\n",
        "my_numbers.<mask>\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bacd1d1f",
      "metadata": {
        "id": "bacd1d1f"
      },
      "outputs": [],
      "source": [
        "fill_mask( python_code )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a84c1f",
      "metadata": {
        "id": "b2a84c1f"
      },
      "source": [
        "# Библиография\n",
        "\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/task_summary.ipynb#scrollTo=QGwpVScF2kZO\n",
        "\n",
        "https://huggingface.co/huggingface/CodeBERTa-small-v1\n",
        "\n",
        "https://huggingface.co/spaces/codeparrot/code-generation-models"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}